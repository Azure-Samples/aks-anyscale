{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8f6fcbd",
   "metadata": {},
   "source": [
    "# Deploy a large-sized LLM\n",
    "\n",
    "<div align=\"left\">\n",
    "<a target=\"_blank\" href=\"https://console.anyscale.com/template-preview/deployment-serve-llm?file=%252Ffiles%252Flarge-size-llm\"><img src=\"https://img.shields.io/badge/ðŸš€ Run_on-Anyscale-9hf\"></a>&nbsp;\n",
    "<a href=\"https://github.com/ray-proj    ect/ray/tree/master/doc/source/serve/tutorials/deployment-serve-llm/large-size-llm\" role=\"button\"><img src=\"https://img.shields.io/static/v1?label=&amp;message=View%20On%20GitHub&amp;color=586069&amp;logo=github&amp;labelColor=2f363d\"></a>&nbsp;\n",
    "</div>\n",
    "\n",
    "A large LLM typically runs on multiple nodes with multiple GPUs, prioritizing peak quality and capability: stronger reasoning, broader knowledge, longer context windows, more robust generalization. When higher latency, complexity, and cost are acceptable trade-offs because you require state-of-the-art results.\n",
    "\n",
    "This tutorial deploys DeepSeek-R1, a large LLM with 685&nbsp;B parameters, using Ray Serve LLM. For smaller models, see [Deploying a small-sized LLM](https://docs.ray.io/en/latest/serve/tutorials/deployment-serve-llm/small-size-llm/README.html) or [Deploying a medium-sized LLM](https://docs.ray.io/en/latest/serve/tutorials/deployment-serve-llm/medium-size-llm/README.html).\n",
    "\n",
    "---\n",
    "\n",
    "## Challenges of large-scale deployments\n",
    "\n",
    "Deploying a 685&nbsp;B-parameter model like DeepSeek-R1 presents significant technical challenges. At this scale, the model can't fit on a single GPU or even a single node. You must distribute it across multiple GPUs and nodes using *tensor parallelism* (splitting tensors within each layer) and *pipeline parallelism* (spreading layers across devices).  \n",
    "\n",
    "Deploying a model of this scale normally requires you to manually launch and coordinate multiple nodes, unless you use a managed platform like [Anyscale](https://www.anyscale.com/), which automates cluster scaling and node orchestration. See [Deploy to production with Anyscale Services](#deploy-to-production-with-anyscale-services) for more details.\n",
    "\n",
    "---\n",
    "\n",
    "## Configure Ray Serve LLM\n",
    "\n",
    "A large-sized LLM is typically deployed across multiple nodes with multiple GPUs. To fully utilize the hardware, set `pipeline_parallel_size` to the number of nodes and `tensor_parallel_size` to the number of GPUs per node, which distributes the modelâ€™s weights evenly.\n",
    "\n",
    "Ray Serve LLM provides multiple [Python APIs](https://docs.ray.io/en/latest/serve/api/index.html#llm-api) for defining your application. Use [`build_openai_app`](https://docs.ray.io/en/latest/serve/api/doc/ray.serve.llm.build_openai_app.html#ray.serve.llm.build_openai_app) to build a full application from your [`LLMConfig`](https://docs.ray.io/en/latest/serve/api/doc/ray.serve.llm.LLMConfig.html#ray.serve.llm.LLMConfig) object.\n",
    "\n",
    "**Optional:** Because Deepseek-R1 is a reasoning model, this tutorial uses vLLMâ€™s built-in reasoning parser to correctly separate its reasoning content from the final response. See [Deploying a reasoning LLM: Parse reasoning outputs](https://docs.ray.io/en/latest/serve/tutorials/deployment-serve-llm/reasoning-llm/README.html#parse-reasoning-outputs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d185d580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-06 16:34:18 [__init__.py:220] No platform detected, vLLM is running on UnspecifiedPlatform\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-06 16:34:19,870\tINFO worker.py:1833 -- Connecting to existing Ray cluster at address: 10.128.5.219:6379...\n",
      "2026-02-06 16:34:19,882\tINFO worker.py:2004 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32mhttps://session-9fyy71sw3bgwajvnjflq7jxd9h.i.anyscaleuserdata.com \u001b[39m\u001b[22m\n",
      "2026-02-06 16:34:19,883\tINFO packaging.py:380 -- Pushing file package 'gcs://_ray_pkg_b0383f9ef0be47c254dfd96fc70a67b56daa506f.zip' (0.05MiB) to Ray cluster...\n",
      "2026-02-06 16:34:19,884\tINFO packaging.py:393 -- Successfully pushed file package 'gcs://_ray_pkg_b0383f9ef0be47c254dfd96fc70a67b56daa506f.zip'.\n",
      "/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/worker.py:2052: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0\n",
      "  warnings.warn(\n",
      "INFO 2026-02-06 16:34:19,893 serve 750734 -- ============== Deployment Options ==============\n",
      "INFO 2026-02-06 16:34:19,894 serve 750734 -- {'autoscaling_config': {'max_replicas': 1, 'min_replicas': 1},\n",
      " 'health_check_period_s': 10,\n",
      " 'health_check_timeout_s': 10,\n",
      " 'max_ongoing_requests': 1000000000,\n",
      " 'name': 'LLMServer:my-deepseek-r1',\n",
      " 'placement_group_bundles': [{'CPU': 1, 'GPU': 1},\n",
      "                             {'GPU': 1},\n",
      "                             {'GPU': 1},\n",
      "                             {'GPU': 1},\n",
      "                             {'GPU': 1},\n",
      "                             {'GPU': 1},\n",
      "                             {'GPU': 1},\n",
      "                             {'GPU': 1},\n",
      "                             {'GPU': 1},\n",
      "                             {'GPU': 1},\n",
      "                             {'GPU': 1},\n",
      "                             {'GPU': 1},\n",
      "                             {'GPU': 1},\n",
      "                             {'GPU': 1},\n",
      "                             {'GPU': 1},\n",
      "                             {'GPU': 1}],\n",
      " 'placement_group_strategy': 'PACK',\n",
      " 'ray_actor_options': {'runtime_env': {'ray_debugger': {'working_dir': '/home/ray/default/large-size-llm'},\n",
      "                                       'worker_process_setup_hook': 'ray.llm._internal.serve._worker_process_setup_hook',\n",
      "                                       'working_dir': 'gcs://_ray_pkg_b0383f9ef0be47c254dfd96fc70a67b56daa506f.zip'}}}\n",
      "INFO 2026-02-06 16:34:19,925 serve 750734 -- ============== Ingress Options ==============\n",
      "INFO 2026-02-06 16:34:19,926 serve 750734 -- {'autoscaling_config': {'initial_replicas': 1,\n",
      "                        'max_replicas': 1,\n",
      "                        'min_replicas': 1,\n",
      "                        'target_ongoing_requests': 1000000000},\n",
      " 'max_ongoing_requests': 1000000000}\n"
     ]
    }
   ],
   "source": [
    "# serve_deepseek_r1.py\n",
    "from ray.serve.llm import LLMConfig, build_openai_app\n",
    "\n",
    "llm_config = LLMConfig(\n",
    "    model_loading_config=dict(\n",
    "        model_id=\"my-deepseek-r1\",\n",
    "        model_source=\"deepseek-ai/DeepSeek-R1\",\n",
    "    ),\n",
    "    experimental_configs=dict(num_ingress_replicas=1),\n",
    "    deployment_config=dict(\n",
    "        autoscaling_config=dict(\n",
    "            min_replicas=1,\n",
    "            max_replicas=1,\n",
    "        )\n",
    "    ),\n",
    "    ### Uncomment if your model is gated and needs your Hugging Face token to access it.\n",
    "    # runtime_env=dict(env_vars={\"HF_TOKEN\": os.environ.get(\"HF_TOKEN\")}),\n",
    "    engine_kwargs=dict(\n",
    "        max_model_len=16384,\n",
    "        # Split weights among 8 GPUs in the node\n",
    "        tensor_parallel_size=8,\n",
    "        pipeline_parallel_size=2,\n",
    "        reasoning_parser=\"deepseek_r1\",  # Optional: separate reasoning content from the final answer\n",
    "    ),\n",
    ")\n",
    "\n",
    "app = build_openai_app({\"llm_configs\": [llm_config]})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2231a5",
   "metadata": {},
   "source": [
    "**Note:** Before moving to a production setup, migrate to a [Serve config file](https://docs.ray.io/en/latest/serve/production-guide/config.html) to make your deployment version-controlled, reproducible, and easier to maintain for CI/CD pipelines. See [Serving LLMs - Quickstart Examples: Production Guide](https://docs.ray.io/en/latest/serve/llm/quick-start.html#production-deployment) for an example.\n",
    "\n",
    "---\n",
    "\n",
    "## Deploy locally\n",
    "\n",
    "**Prerequisites**\n",
    "\n",
    "* Access to GPU compute.\n",
    "* (Optional) A **Hugging Face token** if using gated models. Store it in `export HF_TOKEN=<YOUR-HUGGINGFACE-TOKEN>`.\n",
    "\n",
    "**Note:** Depending on the organization, you can usually request access on the model's Hugging Face page. For example, Metaâ€™s Llama models approval can take anywhere from a few hours to several weeks.\n",
    "\n",
    "**Dependencies:**  \n",
    "```bash\n",
    "pip install \"ray[serve,llm]\"\n",
    "```\n",
    "\n",
    "**Beware**: this is an expensive deployment.\n",
    "\n",
    "---\n",
    "\n",
    "### Launch\n",
    "\n",
    "Follow the instructions at [Configure Ray Serve LLM](#configure-ray-serve-llm) to define your app in a Python module `serve_deepseek_r1.py`.  \n",
    "\n",
    "In a terminal, run:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae9da12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-06 16:34:28,137\tINFO scripts.py:507 -- Running import path: 'serve_deepseek_r1:app'.\n",
      "INFO 02-06 16:34:30 [__init__.py:220] No platform detected, vLLM is running on UnspecifiedPlatform\n",
      "2026-02-06 16:34:31,614\tINFO worker.py:1833 -- Connecting to existing Ray cluster at address: 10.128.5.219:6379...\n",
      "2026-02-06 16:34:31,624\tINFO worker.py:2004 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32mhttps://session-9fyy71sw3bgwajvnjflq7jxd9h.i.anyscaleuserdata.com \u001b[39m\u001b[22m\n",
      "2026-02-06 16:34:31,625\tINFO packaging.py:380 -- Pushing file package 'gcs://_ray_pkg_5ede6c2b362631ca823f8f408ee688ece7ecec40.zip' (0.05MiB) to Ray cluster...\n",
      "2026-02-06 16:34:31,626\tINFO packaging.py:393 -- Successfully pushed file package 'gcs://_ray_pkg_5ede6c2b362631ca823f8f408ee688ece7ecec40.zip'.\n",
      "/home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/worker.py:2052: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0\n",
      "  warnings.warn(\n",
      "INFO 2026-02-06 16:34:31,635 serve 751227 -- ============== Deployment Options ==============\n",
      "INFO 2026-02-06 16:34:31,635 serve 751227 -- {'autoscaling_config': {'max_replicas': 1, 'min_replicas': 1},\n",
      " 'health_check_period_s': 10,\n",
      " 'health_check_timeout_s': 10,\n",
      " 'max_ongoing_requests': 1000000000,\n",
      " 'name': 'LLMServer:my-deepseek-r1',\n",
      " 'placement_group_bundles': [{'CPU': 1, 'GPU': 1},\n",
      "                             {'GPU': 1},\n",
      "                             {'GPU': 1},\n",
      "                             {'GPU': 1},\n",
      "                             {'GPU': 1},\n",
      "                             {'GPU': 1},\n",
      "                             {'GPU': 1},\n",
      "                             {'GPU': 1},\n",
      "                             {'GPU': 1},\n",
      "                             {'GPU': 1},\n",
      "                             {'GPU': 1},\n",
      "                             {'GPU': 1},\n",
      "                             {'GPU': 1},\n",
      "                             {'GPU': 1},\n",
      "                             {'GPU': 1},\n",
      "                             {'GPU': 1}],\n",
      " 'placement_group_strategy': 'PACK',\n",
      " 'ray_actor_options': {'runtime_env': {'ray_debugger': {'working_dir': '/home/ray/default/large-size-llm'},\n",
      "                                       'worker_process_setup_hook': 'ray.llm._internal.serve._worker_process_setup_hook',\n",
      "                                       'working_dir': 'gcs://_ray_pkg_5ede6c2b362631ca823f8f408ee688ece7ecec40.zip'}}}\n",
      "INFO 2026-02-06 16:34:31,663 serve 751227 -- ============== Ingress Options ==============\n",
      "INFO 2026-02-06 16:34:31,664 serve 751227 -- {'autoscaling_config': {'initial_replicas': 1,\n",
      "                        'max_replicas': 1,\n",
      "                        'min_replicas': 1,\n",
      "                        'target_ongoing_requests': 1000000000},\n",
      " 'max_ongoing_requests': 1000000000}\n",
      "INFO 2026-02-06 16:34:33,964 serve 751227 -- Started Serve in namespace \"serve\".\n",
      "INFO 2026-02-06 16:34:33,990 serve 751227 -- Connecting to existing Serve app in namespace \"serve\". New http options will not be applied.\n",
      "\u001b[36m(ProxyActor pid=751438)\u001b[0m INFO 2026-02-06 16:34:33,922 proxy 10.128.5.219 -- Proxy starting on node 1a6ddbbb716b74256e415b58e3dca445abdb4074bbfecbc482406ab0 (HTTP port: 8000).\n",
      "\u001b[36m(ProxyActor pid=751438)\u001b[0m INFO 2026-02-06 16:34:33,961 proxy 10.128.5.219 -- Got updated endpoints: {}.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m INFO 2026-02-06 16:34:34,063 controller 751368 -- Deploying new version of Deployment(name='LLMServer:my-deepseek-r1', app='default') (initial target replicas: 1).\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m INFO 2026-02-06 16:34:34,064 controller 751368 -- Deploying new version of Deployment(name='OpenAiIngress', app='default') (initial target replicas: 1).\n",
      "\u001b[36m(ProxyActor pid=751438)\u001b[0m INFO 2026-02-06 16:34:34,067 proxy 10.128.5.219 -- Got updated endpoints: {Deployment(name='OpenAiIngress', app='default'): EndpointInfo(route='/', app_is_cross_language=False)}.\n",
      "\u001b[36m(ProxyActor pid=751438)\u001b[0m WARNING 2026-02-06 16:34:34,073 proxy 10.128.5.219 -- ANYSCALE_RAY_SERVE_GRPC_RUN_PROXY_ROUTER_SEPARATE_LOOP has been deprecated and will be removed in the ray v2.50.0. Please use RAY_SERVE_RUN_ROUTER_IN_SEPARATE_LOOP instead.\n",
      "\u001b[36m(ProxyActor pid=751438)\u001b[0m INFO 2026-02-06 16:34:34,076 proxy 10.128.5.219 -- Started <ray.serve._private.router.SharedRouterLongPollClient object at 0x7fcbb9d1b850>.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m INFO 2026-02-06 16:34:34,168 controller 751368 -- Adding 1 replica to Deployment(name='LLMServer:my-deepseek-r1', app='default').\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m INFO 2026-02-06 16:34:34,168 controller 751368 -- Assigned rank 0 to new replica 944l93yn during startup\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m INFO 2026-02-06 16:34:34,170 controller 751368 -- Adding 1 replica to Deployment(name='OpenAiIngress', app='default').\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m INFO 2026-02-06 16:34:34,170 controller 751368 -- Assigned rank 0 to new replica 3wbzf2x1 during startup\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m INFO 02-06 16:34:42 [__init__.py:216] Automatically detected platform cuda.\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m INFO 2026-02-06 16:34:43,964 default_LLMServer:my-deepseek-r1 944l93yn -- Running tasks to download model files on worker nodes\n",
      "\u001b[36m(ProxyActor pid=1160, ip=10.128.7.238)\u001b[0m INFO 2026-02-06 16:34:44,241 proxy 10.128.7.238 -- Proxy starting on node 9d5eed264763a3e3998aec43aaee584bd8e882c97d9b6dac25a073d6 (HTTP port: 8000).\n",
      "\u001b[36m(ProxyActor pid=1160, ip=10.128.7.238)\u001b[0m INFO 2026-02-06 16:34:44,306 proxy 10.128.7.238 -- Got updated endpoints: {Deployment(name='OpenAiIngress', app='default'): EndpointInfo(route='/', app_is_cross_language=False)}.\n",
      "\u001b[36m(ProxyActor pid=1160, ip=10.128.7.238)\u001b[0m WARNING 2026-02-06 16:34:44,311 proxy 10.128.7.238 -- ANYSCALE_RAY_SERVE_GRPC_RUN_PROXY_ROUTER_SEPARATE_LOOP has been deprecated and will be removed in the ray v2.50.0. Please use RAY_SERVE_RUN_ROUTER_IN_SEPARATE_LOOP instead.\n",
      "\u001b[36m(ProxyActor pid=1160, ip=10.128.7.238)\u001b[0m INFO 2026-02-06 16:34:44,319 proxy 10.128.7.238 -- Started <ray.serve._private.router.SharedRouterLongPollClient object at 0x7f8cba37cb90>.\n",
      "\u001b[36m(download_model_files pid=2112, ip=10.128.7.238)\u001b[0m No cloud storage mirror configured\n",
      "\u001b[36m(download_model_files pid=2112, ip=10.128.7.238)\u001b[0m INFO 02-06 16:34:49 [__init__.py:216] Automatically detected platform cuda.\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(_get_vllm_engine_config pid=2112, ip=10.128.7.238)\u001b[0m INFO 02-06 16:34:59 [__init__.py:742] Resolved architecture: DeepseekV3ForCausalLM\n",
      "\u001b[36m(_get_vllm_engine_config pid=2112, ip=10.128.7.238)\u001b[0m INFO 02-06 16:35:00 [__init__.py:1815] Using max model len 16384\n",
      "\u001b[36m(_get_vllm_engine_config pid=2112, ip=10.128.7.238)\u001b[0m WARNING 02-06 16:35:01 [_ipex_ops.py:16] Import error msg: No module named 'intel_extension_for_pytorch'\n",
      "\u001b[36m(_get_vllm_engine_config pid=2112, ip=10.128.7.238)\u001b[0m INFO 02-06 16:35:01 [arg_utils.py:1208] Using ray runtime env: {'ray_debugger': {'working_dir': '/home/ray/default/large-size-llm'}, 'working_dir': 'gcs://_ray_pkg_5ede6c2b362631ca823f8f408ee688ece7ecec40.zip', 'worker_process_setup_hook': 'ray.llm._internal.serve._worker_process_setup_hook'}\n",
      "\u001b[36m(_get_vllm_engine_config pid=2112, ip=10.128.7.238)\u001b[0m INFO 02-06 16:35:01 [scheduler.py:222] Chunked prefill is enabled with max_num_batched_tokens=2048.\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m You are using a model of type deepseek_v3 to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
      "\u001b[36m(download_model_files pid=2566, ip=10.128.6.21)\u001b[0m No cloud storage mirror configured\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m You are using a model of type deepseek_v3 to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m INFO 2026-02-06 16:35:03,795 default_LLMServer:my-deepseek-r1 944l93yn -- Clearing the current platform cache ...\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m INFO 2026-02-06 16:35:03,802 default_LLMServer:my-deepseek-r1 944l93yn -- Using executor class: <class 'vllm.v1.executor.ray_distributed_executor.RayDistributedExecutor'>\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:35:04,195 controller 751368 -- Deployment 'LLMServer:my-deepseek-r1' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:35:04,195 controller 751368 -- Deployment 'OpenAiIngress' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m WARNING 02-06 16:35:05 [__init__.py:2974] We must use the `spawn` multiprocessing start method. Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. See https://docs.vllm.ai/en/latest/usage/troubleshooting.html#python-multiprocessing for more information. Reasons: In a Ray actor and can only be spawned\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m INFO 02-06 16:35:09 [__init__.py:216] Automatically detected platform cuda.\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m INFO 02-06 16:35:12 [core.py:654] Waiting for init message from front-end.\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m INFO 02-06 16:35:12 [core.py:76] Initializing a V1 LLM engine (v0.10.2) with config: model='deepseek-ai/DeepSeek-R1', speculative_config=None, tokenizer='deepseek-ai/DeepSeek-R1', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=16384, download_dir=None, load_format=auto, tensor_parallel_size=8, pipeline_parallel_size=2, data_parallel_size=1, disable_custom_all_reduce=False, quantization=fp8, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend='deepseek_r1'), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=my-deepseek-r1, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=False, pooler_config=None, compilation_config={\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\",\"vllm.mamba_mixer2\",\"vllm.mamba_mixer\",\"vllm.short_conv\",\"vllm.linear_attention\",\"vllm.plamo2_mamba_mixer\",\"vllm.gdn_attention\"],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"cudagraph_mode\":1,\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"pass_config\":{},\"max_capture_size\":512,\"local_cache_dir\":null}\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m 2026-02-06 16:35:12,458\tINFO worker.py:1692 -- Using address ses-9fyy71sw3bgwajvnjflq7jxd9h-head:6379 set in the environment variable RAY_ADDRESS\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m 2026-02-06 16:35:12,465\tINFO worker.py:1833 -- Connecting to existing Ray cluster at address: ses-9fyy71sw3bgwajvnjflq7jxd9h-head:6379...\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m 2026-02-06 16:35:12,497\tINFO worker.py:2004 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32mhttps://session-9fyy71sw3bgwajvnjflq7jxd9h.i.anyscaleuserdata.com \u001b[39m\u001b[22m\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m INFO 02-06 16:35:14 [ray_utils.py:324] Using the existing placement group\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m INFO 02-06 16:35:14 [ray_distributed_executor.py:171] use_ray_spmd_worker: True\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m /home/ray/anaconda3/lib/python3.11/site-packages/ray/_private/worker.py:2052: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m   warnings.warn(\n",
      "\u001b[36m(pid=7345, ip=10.128.7.238)\u001b[0m INFO 02-06 16:35:20 [__init__.py:216] Automatically detected platform cuda.\n",
      "\u001b[36m(pid=7484, ip=10.128.7.238)\u001b[0m INFO 02-06 16:35:20 [__init__.py:216] Automatically detected platform cuda.\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m INFO 02-06 16:35:27 [ray_env.py:63] RAY_NON_CARRY_OVER_ENV_VARS from config: set()\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m INFO 02-06 16:35:27 [ray_env.py:65] Copying the following environment variables to workers: ['VLLM_USE_RAY_SPMD_WORKER', 'VLLM_WORKER_MULTIPROC_METHOD', 'VLLM_USE_RAY_COMPILED_DAG', 'LD_LIBRARY_PATH']\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m INFO 02-06 16:35:27 [ray_env.py:68] If certain env vars should NOT be copied, add them to /home/ray/.config/vllm/ray_non_carry_over_env_vars.json file\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(pid=7345)\u001b[0m INFO 02-06 16:35:20 [__init__.py:216] Automatically detected platform cuda.\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:35:34,284 controller 751368 -- Deployment 'LLMServer:my-deepseek-r1' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:35:34,284 controller 751368 -- Deployment 'OpenAiIngress' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(RayWorkerWrapper pid=2656, ip=10.128.6.21)\u001b[0m [W206 16:35:35.274393276 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())\n",
      "\u001b[36m(RayWorkerWrapper pid=7345, ip=10.128.7.238)\u001b[0m [Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15\n",
      "\u001b[36m(RayWorkerWrapper pid=7345, ip=10.128.7.238)\u001b[0m [Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7\n",
      "\u001b[36m(RayWorkerWrapper pid=7345, ip=10.128.7.238)\u001b[0m INFO 02-06 16:35:36 [__init__.py:1433] Found nccl from library libnccl.so.2\n",
      "\u001b[36m(RayWorkerWrapper pid=7345, ip=10.128.7.238)\u001b[0m INFO 02-06 16:35:36 [pynccl.py:70] vLLM is using nccl==2.27.3\n",
      "\u001b[36m(RayWorkerWrapper pid=2653, ip=10.128.6.21)\u001b[0m INFO 02-06 16:35:37 [custom_all_reduce.py:35] Skipping P2P check and trusting the driver's P2P report.\n",
      "\u001b[36m(RayWorkerWrapper pid=2653, ip=10.128.6.21)\u001b[0m INFO 02-06 16:35:37 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3, 4, 5, 6, 7], buffer_handle=(7, 4194304, 6, 'psm_18b6e6d7'), local_subscribe_addr='ipc:///tmp/fe13d02e-c28d-4fcb-8609-90d903200d1d', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "\u001b[36m(RayWorkerWrapper pid=7345, ip=10.128.7.238)\u001b[0m INFO 02-06 16:35:37 [parallel_state.py:1165] rank 1 in world size 16 is assigned as DP rank 0, PP rank 0, TP rank 1, EP rank 1\n",
      "\u001b[36m(RayWorkerWrapper pid=7345, ip=10.128.7.238)\u001b[0m WARNING 02-06 16:35:37 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "\u001b[36m(RayWorkerWrapper pid=2653, ip=10.128.6.21)\u001b[0m INFO 02-06 16:35:37 [gpu_model_runner.py:2338] Starting to load model deepseek-ai/DeepSeek-R1...\n",
      "\u001b[36m(RayWorkerWrapper pid=7364, ip=10.128.7.238)\u001b[0m INFO 02-06 16:35:37 [gpu_model_runner.py:2370] Loading model from scratch...\n",
      "\u001b[36m(RayWorkerWrapper pid=7364, ip=10.128.7.238)\u001b[0m INFO 02-06 16:35:37 [utils.py:125] Hidden layers were unevenly partitioned: [31,30]. This can be manually overridden using the VLLM_PP_LAYER_PARTITION environment variable\n",
      "\u001b[36m(RayWorkerWrapper pid=2659, ip=10.128.6.21)\u001b[0m INFO 02-06 16:35:37 [cuda.py:252] Using Triton MLA backend on V1 engine.\n",
      "\u001b[36m(RayWorkerWrapper pid=7364, ip=10.128.7.238)\u001b[0m WARNING 02-06 16:35:38 [fp8.py:574] CutlassBlockScaledGroupedGemm not supported on the current platform.\n",
      "\u001b[36m(RayWorkerWrapper pid=2653, ip=10.128.6.21)\u001b[0m INFO 02-06 16:35:38 [weight_utils.py:348] Using model weights format ['*.safetensors']\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:36:04,354 controller 751368 -- Deployment 'LLMServer:my-deepseek-r1' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:36:04,354 controller 751368 -- Deployment 'OpenAiIngress' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(RayWorkerWrapper pid=7163, ip=10.128.7.238)\u001b[0m [W206 16:35:35.209711029 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:36:34,426 controller 751368 -- Deployment 'LLMServer:my-deepseek-r1' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:36:34,427 controller 751368 -- Deployment 'OpenAiIngress' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:37:04,505 controller 751368 -- Deployment 'LLMServer:my-deepseek-r1' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:37:04,505 controller 751368 -- Deployment 'OpenAiIngress' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:37:34,572 controller 751368 -- Deployment 'LLMServer:my-deepseek-r1' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:37:34,572 controller 751368 -- Deployment 'OpenAiIngress' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:38:04,669 controller 751368 -- Deployment 'LLMServer:my-deepseek-r1' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:38:04,669 controller 751368 -- Deployment 'OpenAiIngress' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:38:34,759 controller 751368 -- Deployment 'LLMServer:my-deepseek-r1' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:38:34,759 controller 751368 -- Deployment 'OpenAiIngress' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:39:04,834 controller 751368 -- Deployment 'LLMServer:my-deepseek-r1' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:39:04,834 controller 751368 -- Deployment 'OpenAiIngress' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:39:34,915 controller 751368 -- Deployment 'LLMServer:my-deepseek-r1' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:39:34,915 controller 751368 -- Deployment 'OpenAiIngress' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(autoscaler +5m34s)\u001b[0m Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.\n",
      "\u001b[36m(autoscaler +5m22s)\u001b[0m Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:40:05,010 controller 751368 -- Deployment 'LLMServer:my-deepseek-r1' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:40:05,010 controller 751368 -- Deployment 'OpenAiIngress' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:40:35,082 controller 751368 -- Deployment 'LLMServer:my-deepseek-r1' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:40:35,083 controller 751368 -- Deployment 'OpenAiIngress' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:41:05,158 controller 751368 -- Deployment 'LLMServer:my-deepseek-r1' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:41:05,159 controller 751368 -- Deployment 'OpenAiIngress' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:41:35,243 controller 751368 -- Deployment 'LLMServer:my-deepseek-r1' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:41:35,243 controller 751368 -- Deployment 'OpenAiIngress' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:42:05,324 controller 751368 -- Deployment 'LLMServer:my-deepseek-r1' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:42:05,325 controller 751368 -- Deployment 'OpenAiIngress' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:42:35,396 controller 751368 -- Deployment 'LLMServer:my-deepseek-r1' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:42:35,396 controller 751368 -- Deployment 'OpenAiIngress' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:43:05,474 controller 751368 -- Deployment 'LLMServer:my-deepseek-r1' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:43:05,475 controller 751368 -- Deployment 'OpenAiIngress' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:43:35,552 controller 751368 -- Deployment 'LLMServer:my-deepseek-r1' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:43:35,552 controller 751368 -- Deployment 'OpenAiIngress' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:44:05,633 controller 751368 -- Deployment 'LLMServer:my-deepseek-r1' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:44:05,634 controller 751368 -- Deployment 'OpenAiIngress' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:44:35,712 controller 751368 -- Deployment 'LLMServer:my-deepseek-r1' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:44:35,712 controller 751368 -- Deployment 'OpenAiIngress' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:45:05,790 controller 751368 -- Deployment 'LLMServer:my-deepseek-r1' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:45:05,790 controller 751368 -- Deployment 'OpenAiIngress' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:45:35,866 controller 751368 -- Deployment 'LLMServer:my-deepseek-r1' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:45:35,866 controller 751368 -- Deployment 'OpenAiIngress' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:46:05,944 controller 751368 -- Deployment 'LLMServer:my-deepseek-r1' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:46:05,944 controller 751368 -- Deployment 'OpenAiIngress' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:46:36,039 controller 751368 -- Deployment 'LLMServer:my-deepseek-r1' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:46:36,039 controller 751368 -- Deployment 'OpenAiIngress' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:47:06,112 controller 751368 -- Deployment 'LLMServer:my-deepseek-r1' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:47:06,112 controller 751368 -- Deployment 'OpenAiIngress' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:47:36,186 controller 751368 -- Deployment 'LLMServer:my-deepseek-r1' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:47:36,186 controller 751368 -- Deployment 'OpenAiIngress' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:48:06,276 controller 751368 -- Deployment 'LLMServer:my-deepseek-r1' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:48:06,276 controller 751368 -- Deployment 'OpenAiIngress' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:48:36,352 controller 751368 -- Deployment 'LLMServer:my-deepseek-r1' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:48:36,353 controller 751368 -- Deployment 'OpenAiIngress' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:49:06,430 controller 751368 -- Deployment 'LLMServer:my-deepseek-r1' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:49:06,430 controller 751368 -- Deployment 'OpenAiIngress' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:49:36,513 controller 751368 -- Deployment 'LLMServer:my-deepseek-r1' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:49:36,514 controller 751368 -- Deployment 'OpenAiIngress' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:50:06,594 controller 751368 -- Deployment 'LLMServer:my-deepseek-r1' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:50:06,594 controller 751368 -- Deployment 'OpenAiIngress' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:50:36,673 controller 751368 -- Deployment 'LLMServer:my-deepseek-r1' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:50:36,674 controller 751368 -- Deployment 'OpenAiIngress' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:51:06,758 controller 751368 -- Deployment 'LLMServer:my-deepseek-r1' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:51:06,758 controller 751368 -- Deployment 'OpenAiIngress' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:51:36,834 controller 751368 -- Deployment 'LLMServer:my-deepseek-r1' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:51:36,835 controller 751368 -- Deployment 'OpenAiIngress' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:52:06,907 controller 751368 -- Deployment 'LLMServer:my-deepseek-r1' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:52:06,907 controller 751368 -- Deployment 'OpenAiIngress' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:52:36,983 controller 751368 -- Deployment 'LLMServer:my-deepseek-r1' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:52:36,983 controller 751368 -- Deployment 'OpenAiIngress' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(RayWorkerWrapper pid=2653, ip=10.128.6.21)\u001b[0m INFO 02-06 16:52:54 [weight_utils.py:369] Time spent downloading weights for deepseek-ai/DeepSeek-R1: 1036.375568 seconds\n",
      "\u001b[36m(RayWorkerWrapper pid=2659, ip=10.128.6.21)\u001b[0m [Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(RayWorkerWrapper pid=2659, ip=10.128.6.21)\u001b[0m INFO 02-06 16:35:37 [__init__.py:1433] Found nccl from library libnccl.so.2\u001b[32m [repeated 31x across cluster]\u001b[0m\n",
      "\u001b[36m(RayWorkerWrapper pid=2659, ip=10.128.6.21)\u001b[0m INFO 02-06 16:35:37 [pynccl.py:70] vLLM is using nccl==2.27.3\u001b[32m [repeated 31x across cluster]\u001b[0m\n",
      "\u001b[36m(RayWorkerWrapper pid=7579, ip=10.128.7.238)\u001b[0m INFO 02-06 16:35:37 [custom_all_reduce.py:35] Skipping P2P check and trusting the driver's P2P report.\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(RayWorkerWrapper pid=7163, ip=10.128.7.238)\u001b[0m INFO 02-06 16:35:37 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3, 4, 5, 6, 7], buffer_handle=(7, 4194304, 6, 'psm_ded737f4'), local_subscribe_addr='ipc:///tmp/d8e466e4-92c3-4b92-a8b3-bbcb01a02bc1', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "\u001b[36m(RayWorkerWrapper pid=2659, ip=10.128.6.21)\u001b[0m INFO 02-06 16:35:37 [parallel_state.py:1165] rank 14 in world size 16 is assigned as DP rank 0, PP rank 1, TP rank 6, EP rank 6\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(RayWorkerWrapper pid=2659, ip=10.128.6.21)\u001b[0m WARNING 02-06 16:35:37 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(RayWorkerWrapper pid=7579, ip=10.128.7.238)\u001b[0m INFO 02-06 16:35:37 [gpu_model_runner.py:2338] Starting to load model deepseek-ai/DeepSeek-R1...\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(RayWorkerWrapper pid=2658, ip=10.128.6.21)\u001b[0m INFO 02-06 16:35:38 [gpu_model_runner.py:2370] Loading model from scratch...\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(RayWorkerWrapper pid=2658, ip=10.128.6.21)\u001b[0m INFO 02-06 16:35:38 [utils.py:125] Hidden layers were unevenly partitioned: [31,30]. This can be manually overridden using the VLLM_PP_LAYER_PARTITION environment variable\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(RayWorkerWrapper pid=2658, ip=10.128.6.21)\u001b[0m INFO 02-06 16:35:38 [cuda.py:252] Using Triton MLA backend on V1 engine.\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(RayWorkerWrapper pid=2658, ip=10.128.6.21)\u001b[0m WARNING 02-06 16:35:38 [fp8.py:574] CutlassBlockScaledGroupedGemm not supported on the current platform.\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(RayWorkerWrapper pid=2658, ip=10.128.6.21)\u001b[0m INFO 02-06 16:35:38 [weight_utils.py:348] Using model weights format ['*.safetensors']\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(RayWorkerWrapper pid=7574, ip=10.128.7.238)\u001b[0m INFO 02-06 16:53:05 [weight_utils.py:369] Time spent downloading weights for deepseek-ai/DeepSeek-R1: 1047.138554 seconds\n",
      "Loading safetensors checkpoint shards:   0% Completed | 0/163 [00:00<?, ?it/s]\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=7163)\u001b[0m [W206 16:35:35.209711029 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:53:07,060 controller 751368 -- Deployment 'LLMServer:my-deepseek-r1' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:53:07,060 controller 751368 -- Deployment 'OpenAiIngress' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "Loading safetensors checkpoint shards:   1% Completed | 2/163 [00:00<00:32,  4.92it/s]\n",
      "Loading safetensors checkpoint shards:   0% Completed | 0/163 [00:00<?, ?it/s][0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=7163)\u001b[0m \n",
      "Loading safetensors checkpoint shards:  13% Completed | 21/163 [00:05<00:44,  3.19it/s]\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "Loading safetensors checkpoint shards:  19% Completed | 31/163 [00:11<01:13,  1.78it/s]\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "Loading safetensors checkpoint shards:  30% Completed | 49/163 [00:16<00:48,  2.37it/s]\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
      "Loading safetensors checkpoint shards:  42% Completed | 69/163 [00:21<00:25,  3.63it/s]\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
      "Loading safetensors checkpoint shards:  50% Completed | 81/163 [00:27<00:32,  2.53it/s]\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[36m(RayWorkerWrapper pid=2653, ip=10.128.6.21)\u001b[0m INFO 02-06 16:53:34 [default_loader.py:268] Loading weights took 39.71 seconds\n",
      "\u001b[36m(RayWorkerWrapper pid=2653, ip=10.128.6.21)\u001b[0m WARNING 02-06 16:53:34 [marlin_utils_fp8.py:80] Your GPU does not have native support for FP8 computation but FP8 quantization is being used. Weight-only FP8 compression will be used leveraging the Marlin kernel. This may degrade performance for compute-heavy workloads.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:53:37,133 controller 751368 -- Deployment 'LLMServer:my-deepseek-r1' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:53:37,133 controller 751368 -- Deployment 'OpenAiIngress' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(RayWorkerWrapper pid=2653, ip=10.128.6.21)\u001b[0m INFO 02-06 16:53:37 [gpu_model_runner.py:2392] Model loading took 41.6739 GiB and 1078.949043 seconds\n",
      "Loading safetensors checkpoint shards:  57% Completed | 93/163 [00:32<00:23,  3.04it/s]\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "Loading safetensors checkpoint shards:  63% Completed | 103/163 [00:37<00:31,  1.89it/s]\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[36m(RayWorkerWrapper pid=7574, ip=10.128.7.238)\u001b[0m INFO 02-06 16:53:46 [default_loader.py:268] Loading weights took 40.35 seconds\n",
      "\u001b[36m(RayWorkerWrapper pid=7574, ip=10.128.7.238)\u001b[0m WARNING 02-06 16:53:46 [marlin_utils_fp8.py:80] Your GPU does not have native support for FP8 computation but FP8 quantization is being used. Weight-only FP8 compression will be used leveraging the Marlin kernel. This may degrade performance for compute-heavy workloads.\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=7345)\u001b[0m [Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=7345)\u001b[0m [Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(pid=2660, ip=10.128.6.21)\u001b[0m INFO 02-06 16:35:24 [__init__.py:216] Automatically detected platform cuda.\u001b[32m [repeated 15x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=7345)\u001b[0m INFO 02-06 16:35:36 [__init__.py:1433] Found nccl from library libnccl.so.2\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=7345)\u001b[0m INFO 02-06 16:35:36 [pynccl.py:70] vLLM is using nccl==2.27.3\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=2653, ip=10.128.6.21)\u001b[0m INFO 02-06 16:35:37 [custom_all_reduce.py:35] Skipping P2P check and trusting the driver's P2P report.\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=2653, ip=10.128.6.21)\u001b[0m INFO 02-06 16:35:37 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3, 4, 5, 6, 7], buffer_handle=(7, 4194304, 6, 'psm_18b6e6d7'), local_subscribe_addr='ipc:///tmp/fe13d02e-c28d-4fcb-8609-90d903200d1d', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=7345)\u001b[0m INFO 02-06 16:35:37 [parallel_state.py:1165] rank 1 in world size 16 is assigned as DP rank 0, PP rank 0, TP rank 1, EP rank 1\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=7345)\u001b[0m WARNING 02-06 16:35:37 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=2653, ip=10.128.6.21)\u001b[0m INFO 02-06 16:35:37 [gpu_model_runner.py:2338] Starting to load model deepseek-ai/DeepSeek-R1...\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=7364)\u001b[0m INFO 02-06 16:35:37 [gpu_model_runner.py:2370] Loading model from scratch...\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=7364)\u001b[0m INFO 02-06 16:35:37 [utils.py:125] Hidden layers were unevenly partitioned: [31,30]. This can be manually overridden using the VLLM_PP_LAYER_PARTITION environment variable\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=2659, ip=10.128.6.21)\u001b[0m INFO 02-06 16:35:37 [cuda.py:252] Using Triton MLA backend on V1 engine.\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=7364)\u001b[0m WARNING 02-06 16:35:38 [fp8.py:574] CutlassBlockScaledGroupedGemm not supported on the current platform.\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=2653, ip=10.128.6.21)\u001b[0m INFO 02-06 16:35:38 [weight_utils.py:348] Using model weights format ['*.safetensors']\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(autoscaler +4m44s, ip=10.128.5.219)\u001b[0m Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=2653, ip=10.128.6.21)\u001b[0m INFO 02-06 16:52:54 [weight_utils.py:369] Time spent downloading weights for deepseek-ai/DeepSeek-R1: 1036.375568 seconds\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=2659, ip=10.128.6.21)\u001b[0m [Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7\u001b[32m [repeated 94x across cluster]\u001b[0m\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=2659, ip=10.128.6.21)\u001b[0m INFO 02-06 16:35:37 [__init__.py:1433] Found nccl from library libnccl.so.2\u001b[32m [repeated 31x across cluster]\u001b[0m\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=2659, ip=10.128.6.21)\u001b[0m INFO 02-06 16:35:37 [pynccl.py:70] vLLM is using nccl==2.27.3\u001b[32m [repeated 31x across cluster]\u001b[0m\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=7579)\u001b[0m INFO 02-06 16:35:37 [custom_all_reduce.py:35] Skipping P2P check and trusting the driver's P2P report.\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=7163)\u001b[0m INFO 02-06 16:35:37 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3, 4, 5, 6, 7], buffer_handle=(7, 4194304, 6, 'psm_ded737f4'), local_subscribe_addr='ipc:///tmp/d8e466e4-92c3-4b92-a8b3-bbcb01a02bc1', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=2659, ip=10.128.6.21)\u001b[0m INFO 02-06 16:35:37 [parallel_state.py:1165] rank 14 in world size 16 is assigned as DP rank 0, PP rank 1, TP rank 6, EP rank 6\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=2659, ip=10.128.6.21)\u001b[0m WARNING 02-06 16:35:37 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=7579)\u001b[0m INFO 02-06 16:35:37 [gpu_model_runner.py:2338] Starting to load model deepseek-ai/DeepSeek-R1...\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=2658, ip=10.128.6.21)\u001b[0m INFO 02-06 16:35:38 [gpu_model_runner.py:2370] Loading model from scratch...\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=2658, ip=10.128.6.21)\u001b[0m INFO 02-06 16:35:38 [utils.py:125] Hidden layers were unevenly partitioned: [31,30]. This can be manually overridden using the VLLM_PP_LAYER_PARTITION environment variable\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=2658, ip=10.128.6.21)\u001b[0m INFO 02-06 16:35:38 [cuda.py:252] Using Triton MLA backend on V1 engine.\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=2658, ip=10.128.6.21)\u001b[0m WARNING 02-06 16:35:38 [fp8.py:574] CutlassBlockScaledGroupedGemm not supported on the current platform.\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=2658, ip=10.128.6.21)\u001b[0m INFO 02-06 16:35:38 [weight_utils.py:348] Using model weights format ['*.safetensors']\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=7574)\u001b[0m INFO 02-06 16:53:05 [weight_utils.py:369] Time spent downloading weights for deepseek-ai/DeepSeek-R1: 1047.138554 seconds\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=2653, ip=10.128.6.21)\u001b[0m INFO 02-06 16:53:34 [default_loader.py:268] Loading weights took 39.71 seconds\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=2653, ip=10.128.6.21)\u001b[0m WARNING 02-06 16:53:34 [marlin_utils_fp8.py:80] Your GPU does not have native support for FP8 computation but FP8 quantization is being used. Weight-only FP8 compression will be used leveraging the Marlin kernel. This may degrade performance for compute-heavy workloads.\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=2653, ip=10.128.6.21)\u001b[0m INFO 02-06 16:53:37 [gpu_model_runner.py:2392] Model loading took 41.6739 GiB and 1078.949043 seconds\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=7574)\u001b[0m INFO 02-06 16:53:46 [default_loader.py:268] Loading weights took 40.35 seconds\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=7574)\u001b[0m WARNING 02-06 16:53:46 [marlin_utils_fp8.py:80] Your GPU does not have native support for FP8 computation but FP8 quantization is being used. Weight-only FP8 compression will be used leveraging the Marlin kernel. This may degrade performance for compute-heavy workloads.\n",
      "Loading safetensors checkpoint shards:  71% Completed | 115/163 [00:42<00:15,  3.05it/s]\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "Loading safetensors checkpoint shards:  79% Completed | 128/163 [00:47<00:17,  2.04it/s]\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "\u001b[36m(RayWorkerWrapper pid=2654, ip=10.128.6.21)\u001b[0m INFO 02-06 16:53:59 [default_loader.py:268] Loading weights took 62.64 seconds\n",
      "\u001b[36m(RayWorkerWrapper pid=2654, ip=10.128.6.21)\u001b[0m WARNING 02-06 16:53:59 [marlin_utils_fp8.py:80] Your GPU does not have native support for FP8 computation but FP8 quantization is being used. Weight-only FP8 compression will be used leveraging the Marlin kernel. This may degrade performance for compute-heavy workloads.\n",
      "\u001b[36m(RayWorkerWrapper pid=7574, ip=10.128.7.238)\u001b[0m INFO 02-06 16:53:48 [gpu_model_runner.py:2392] Model loading took 39.1713 GiB and 1090.283271 seconds\n",
      "\u001b[36m(RayWorkerWrapper pid=2656, ip=10.128.6.21)\u001b[0m INFO 02-06 16:53:59 [default_loader.py:268] Loading weights took 62.14 seconds\n",
      "\u001b[36m(RayWorkerWrapper pid=2656, ip=10.128.6.21)\u001b[0m WARNING 02-06 16:53:59 [marlin_utils_fp8.py:80] Your GPU does not have native support for FP8 computation but FP8 quantization is being used. Weight-only FP8 compression will be used leveraging the Marlin kernel. This may degrade performance for compute-heavy workloads.\n",
      "Loading safetensors checkpoint shards:  87% Completed | 142/163 [00:52<00:06,  3.25it/s]\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "\u001b[36m(RayWorkerWrapper pid=2660, ip=10.128.6.21)\u001b[0m INFO 02-06 16:54:01 [gpu_model_runner.py:2392] Model loading took 41.6739 GiB and 1102.924501 seconds\n",
      "Loading safetensors checkpoint shards:  95% Completed | 155/163 [00:57<00:02,  2.68it/s]\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:54:07,216 controller 751368 -- Deployment 'LLMServer:my-deepseek-r1' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:54:07,217 controller 751368 -- Deployment 'OpenAiIngress' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(RayWorkerWrapper pid=7345, ip=10.128.7.238)\u001b[0m INFO 02-06 16:54:08 [default_loader.py:268] Loading weights took 61.10 seconds\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(RayWorkerWrapper pid=7345, ip=10.128.7.238)\u001b[0m WARNING 02-06 16:54:08 [marlin_utils_fp8.py:80] Your GPU does not have native support for FP8 computation but FP8 quantization is being used. Weight-only FP8 compression will be used leveraging the Marlin kernel. This may degrade performance for compute-heavy workloads.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(RayWorkerWrapper pid=2658, ip=10.128.6.21)\u001b[0m INFO 02-06 16:54:01 [gpu_model_runner.py:2392] Model loading took 41.6739 GiB and 1102.860211 seconds\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(RayWorkerWrapper pid=7163, ip=10.128.7.238)\u001b[0m \n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=7163)\u001b[0m \n",
      "\u001b[36m(RayWorkerWrapper pid=2654, ip=10.128.6.21)\u001b[0m INFO 02-06 16:54:17 [backends.py:539] Using cache directory: /home/ray/.cache/vllm/torch_compile_cache/0a4aa8c46f/rank_9_0/backbone for vLLM's torch.compile\n",
      "\u001b[36m(RayWorkerWrapper pid=2654, ip=10.128.6.21)\u001b[0m INFO 02-06 16:54:17 [backends.py:550] Dynamo bytecode transform time: 6.24 s\n",
      "\u001b[36m(RayWorkerWrapper pid=7579, ip=10.128.7.238)\u001b[0m INFO 02-06 16:54:08 [default_loader.py:268] Loading weights took 61.32 seconds\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(RayWorkerWrapper pid=7579, ip=10.128.7.238)\u001b[0m WARNING 02-06 16:54:08 [marlin_utils_fp8.py:80] Your GPU does not have native support for FP8 computation but FP8 quantization is being used. Weight-only FP8 compression will be used leveraging the Marlin kernel. This may degrade performance for compute-heavy workloads.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(RayWorkerWrapper pid=7579, ip=10.128.7.238)\u001b[0m INFO 02-06 16:54:11 [gpu_model_runner.py:2392] Model loading took 39.1713 GiB and 1112.681312 seconds\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(RayWorkerWrapper pid=2653, ip=10.128.6.21)\u001b[0m INFO 02-06 16:54:21 [backends.py:194] Cache the graph for dynamic shape for later use\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:54:37,298 controller 751368 -- Deployment 'LLMServer:my-deepseek-r1' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:54:37,298 controller 751368 -- Deployment 'OpenAiIngress' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "Loading safetensors checkpoint shards: 100% Completed | 163/163 [01:01<00:00,  2.65it/s]\u001b[32m [repeated 17x across cluster]\u001b[0mRayWorkerWrapper pid=7163)\u001b[0m \n",
      "\u001b[36m(RayWorkerWrapper pid=2660, ip=10.128.6.21)\u001b[0m INFO 02-06 16:55:03 [backends.py:215] Compiling a graph for dynamic shape takes 44.78 s\n",
      "\u001b[36m(RayWorkerWrapper pid=7364, ip=10.128.7.238)\u001b[0m INFO 02-06 16:54:18 [backends.py:539] Using cache directory: /home/ray/.cache/vllm/torch_compile_cache/92d53832c9/rank_2_0/backbone for vLLM's torch.compile\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(RayWorkerWrapper pid=7364, ip=10.128.7.238)\u001b[0m INFO 02-06 16:54:18 [backends.py:550] Dynamo bytecode transform time: 7.06 s\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(RayWorkerWrapper pid=7579, ip=10.128.7.238)\u001b[0m INFO 02-06 16:54:22 [backends.py:194] Cache the graph for dynamic shape for later use\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(RayWorkerWrapper pid=2653, ip=10.128.6.21)\u001b[0m INFO 02-06 16:55:05 [marlin_utils.py:364] Marlin kernel can achieve better performance for small size_n with experimental use_atomic_add feature. You can consider set environment variable VLLM_MARLIN_USE_ATOMIC_ADD to 1 if possible.\n",
      "\u001b[36m(RayWorkerWrapper pid=2654, ip=10.128.6.21)\u001b[0m INFO 02-06 16:55:06 [marlin_utils.py:353] You are running Marlin kernel with bf16 on GPUs before SM90. You can consider change to fp16 to achieve better performance if possible.\n",
      "\u001b[36m(RayWorkerWrapper pid=2653, ip=10.128.6.21)\u001b[0m INFO 02-06 16:55:07 [monitor.py:34] torch.compile takes 52.48 s in total\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:55:07,372 controller 751368 -- Deployment 'LLMServer:my-deepseek-r1' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m WARNING 2026-02-06 16:55:07,372 controller 751368 -- Deployment 'OpenAiIngress' in application 'default' has 1 replicas that have taken more than 30s to initialize.\n",
      "\u001b[36m(ServeController pid=751368)\u001b[0m This may be caused by a slow __init__ or reconfigure method.\n",
      "\u001b[36m(RayWorkerWrapper pid=7579, ip=10.128.7.238)\u001b[0m INFO 02-06 16:55:06 [backends.py:215] Compiling a graph for dynamic shape takes 47.21 s\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(RayWorkerWrapper pid=2655, ip=10.128.6.21)\u001b[0m INFO 02-06 16:55:08 [gpu_worker.py:298] Available KV cache memory: 27.27 GiB\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=7574)\u001b[0m INFO 02-06 16:53:48 [gpu_model_runner.py:2392] Model loading took 39.1713 GiB and 1090.283271 seconds\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=2654, ip=10.128.6.21)\u001b[0m INFO 02-06 16:53:59 [default_loader.py:268] Loading weights took 62.64 seconds\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=2654, ip=10.128.6.21)\u001b[0m WARNING 02-06 16:53:59 [marlin_utils_fp8.py:80] Your GPU does not have native support for FP8 computation but FP8 quantization is being used. Weight-only FP8 compression will be used leveraging the Marlin kernel. This may degrade performance for compute-heavy workloads.\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=2660, ip=10.128.6.21)\u001b[0m INFO 02-06 16:54:01 [gpu_model_runner.py:2392] Model loading took 41.6739 GiB and 1102.924501 seconds\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=7345)\u001b[0m INFO 02-06 16:54:08 [default_loader.py:268] Loading weights took 61.10 seconds\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=7345)\u001b[0m WARNING 02-06 16:54:08 [marlin_utils_fp8.py:80] Your GPU does not have native support for FP8 computation but FP8 quantization is being used. Weight-only FP8 compression will be used leveraging the Marlin kernel. This may degrade performance for compute-heavy workloads.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=2658, ip=10.128.6.21)\u001b[0m INFO 02-06 16:54:01 [gpu_model_runner.py:2392] Model loading took 41.6739 GiB and 1102.860211 seconds\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=2654, ip=10.128.6.21)\u001b[0m INFO 02-06 16:54:17 [backends.py:539] Using cache directory: /home/ray/.cache/vllm/torch_compile_cache/0a4aa8c46f/rank_9_0/backbone for vLLM's torch.compile\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=2654, ip=10.128.6.21)\u001b[0m INFO 02-06 16:54:17 [backends.py:550] Dynamo bytecode transform time: 6.24 s\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=7579)\u001b[0m INFO 02-06 16:54:08 [default_loader.py:268] Loading weights took 61.32 seconds\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=7579)\u001b[0m WARNING 02-06 16:54:08 [marlin_utils_fp8.py:80] Your GPU does not have native support for FP8 computation but FP8 quantization is being used. Weight-only FP8 compression will be used leveraging the Marlin kernel. This may degrade performance for compute-heavy workloads.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=7579)\u001b[0m INFO 02-06 16:54:11 [gpu_model_runner.py:2392] Model loading took 39.1713 GiB and 1112.681312 seconds\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=2653, ip=10.128.6.21)\u001b[0m INFO 02-06 16:54:21 [backends.py:194] Cache the graph for dynamic shape for later use\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=7364)\u001b[0m INFO 02-06 16:54:18 [backends.py:539] Using cache directory: /home/ray/.cache/vllm/torch_compile_cache/92d53832c9/rank_2_0/backbone for vLLM's torch.compile\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=7364)\u001b[0m INFO 02-06 16:54:18 [backends.py:550] Dynamo bytecode transform time: 7.06 s\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=7579)\u001b[0m INFO 02-06 16:54:22 [backends.py:194] Cache the graph for dynamic shape for later use\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=7579)\u001b[0m INFO 02-06 16:55:06 [backends.py:215] Compiling a graph for dynamic shape takes 47.21 s\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m INFO 02-06 16:55:10 [kv_cache_utils.py:864] GPU KV cache size: 935,888 tokens\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m INFO 02-06 16:55:10 [kv_cache_utils.py:868] Maximum concurrency for 16,384 tokens per request: 57.12x\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m INFO 02-06 16:55:10 [kv_cache_utils.py:864] GPU KV cache size: 935,888 tokens\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m INFO 02-06 16:55:10 [kv_cache_utils.py:868] Maximum concurrency for 16,384 tokens per request: 57.12x\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m INFO 02-06 16:55:10 [kv_cache_utils.py:864] GPU KV cache size: 935,888 tokens\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m INFO 02-06 16:55:10 [kv_cache_utils.py:868] Maximum concurrency for 16,384 tokens per request: 57.12x\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m INFO 02-06 16:55:10 [kv_cache_utils.py:864] GPU KV cache size: 935,888 tokens\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m INFO 02-06 16:55:10 [kv_cache_utils.py:868] Maximum concurrency for 16,384 tokens per request: 57.12x\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m INFO 02-06 16:55:10 [kv_cache_utils.py:864] GPU KV cache size: 935,888 tokens\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m INFO 02-06 16:55:10 [kv_cache_utils.py:868] Maximum concurrency for 16,384 tokens per request: 57.12x\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m INFO 02-06 16:55:10 [kv_cache_utils.py:864] GPU KV cache size: 935,888 tokens\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m INFO 02-06 16:55:10 [kv_cache_utils.py:868] Maximum concurrency for 16,384 tokens per request: 57.12x\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m INFO 02-06 16:55:10 [kv_cache_utils.py:864] GPU KV cache size: 935,888 tokens\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m INFO 02-06 16:55:10 [kv_cache_utils.py:868] Maximum concurrency for 16,384 tokens per request: 57.12x\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m INFO 02-06 16:55:10 [kv_cache_utils.py:864] GPU KV cache size: 935,888 tokens\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m INFO 02-06 16:55:10 [kv_cache_utils.py:868] Maximum concurrency for 16,384 tokens per request: 57.12x\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m INFO 02-06 16:55:10 [kv_cache_utils.py:864] GPU KV cache size: 847,312 tokens\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m INFO 02-06 16:55:10 [kv_cache_utils.py:868] Maximum concurrency for 16,384 tokens per request: 51.72x\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m INFO 02-06 16:55:10 [kv_cache_utils.py:864] GPU KV cache size: 847,312 tokens\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m INFO 02-06 16:55:10 [kv_cache_utils.py:868] Maximum concurrency for 16,384 tokens per request: 51.72x\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m INFO 02-06 16:55:10 [kv_cache_utils.py:864] GPU KV cache size: 847,312 tokens\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m INFO 02-06 16:55:10 [kv_cache_utils.py:868] Maximum concurrency for 16,384 tokens per request: 51.72x\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m INFO 02-06 16:55:10 [kv_cache_utils.py:864] GPU KV cache size: 847,312 tokens\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m INFO 02-06 16:55:10 [kv_cache_utils.py:868] Maximum concurrency for 16,384 tokens per request: 51.72x\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m INFO 02-06 16:55:10 [kv_cache_utils.py:864] GPU KV cache size: 847,312 tokens\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m INFO 02-06 16:55:10 [kv_cache_utils.py:868] Maximum concurrency for 16,384 tokens per request: 51.72x\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m INFO 02-06 16:55:10 [kv_cache_utils.py:864] GPU KV cache size: 847,312 tokens\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m INFO 02-06 16:55:10 [kv_cache_utils.py:868] Maximum concurrency for 16,384 tokens per request: 51.72x\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m INFO 02-06 16:55:10 [kv_cache_utils.py:864] GPU KV cache size: 847,312 tokens\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m INFO 02-06 16:55:10 [kv_cache_utils.py:868] Maximum concurrency for 16,384 tokens per request: 51.72x\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m INFO 02-06 16:55:10 [kv_cache_utils.py:864] GPU KV cache size: 847,312 tokens\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m INFO 02-06 16:55:10 [kv_cache_utils.py:868] Maximum concurrency for 16,384 tokens per request: 51.72x\n",
      "Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/67 [00:00<?, ?it/s]\n",
      "Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   1%|â–         | 1/67 [00:00<00:06,  9.85it/s]\n",
      "Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/67 [00:00<?, ?it/s]eCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=7163)\u001b[0m \n",
      "Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 56/67 [00:05<00:01, 10.76it/s]\u001b[32m [repeated 56x across cluster]\u001b[0m\n",
      "Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 62/67 [00:05<00:00, 10.74it/s]\n",
      "\u001b[36m(RayWorkerWrapper pid=7345, ip=10.128.7.238)\u001b[0m INFO 02-06 16:55:17 [custom_all_reduce.py:203] Registering 4221 cuda graph addresses\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=2653, ip=10.128.6.21)\u001b[0m INFO 02-06 16:55:05 [marlin_utils.py:364] Marlin kernel can achieve better performance for small size_n with experimental use_atomic_add feature. You can consider set environment variable VLLM_MARLIN_USE_ATOMIC_ADD to 1 if possible.\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=2654, ip=10.128.6.21)\u001b[0m INFO 02-06 16:55:06 [marlin_utils.py:353] You are running Marlin kernel with bf16 on GPUs before SM90. You can consider change to fp16 to achieve better performance if possible.\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=2653, ip=10.128.6.21)\u001b[0m INFO 02-06 16:55:07 [monitor.py:34] torch.compile takes 52.48 s in total\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=2660, ip=10.128.6.21)\u001b[0m INFO 02-06 16:55:03 [backends.py:215] Compiling a graph for dynamic shape takes 44.78 s\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=2655, ip=10.128.6.21)\u001b[0m INFO 02-06 16:55:08 [gpu_worker.py:298] Available KV cache memory: 27.27 GiB\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(RayWorkerWrapper pid=7345, ip=10.128.7.238)\u001b[0m INFO 02-06 16:55:18 [gpu_model_runner.py:3118] Graph capturing finished in 8 secs, took 0.85 GiB\n",
      "\u001b[36m(RayWorkerWrapper pid=7345, ip=10.128.7.238)\u001b[0m INFO 02-06 16:55:18 [gpu_worker.py:391] Free memory on device (78.76/79.25 GiB) on startup. Desired GPU memory utilization is (0.9, 71.33 GiB). Actual usage is 39.17 GiB for weight, 0.41 GiB for peak activation, 0.62 GiB for non-torch memory, and 0.85 GiB for CUDAGraph memory. Replace gpu_memory_utilization config with `--kv-cache-memory=32349134745` to fit into requested memory, or `--kv-cache-memory=40333346304` to fully utilize gpu memory. Current kv cache memory in use is 33422876569 bytes.\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=7345)\u001b[0m INFO 02-06 16:55:07 [marlin_utils.py:364] Marlin kernel can achieve better performance for small size_n with experimental use_atomic_add feature. You can consider set environment variable VLLM_MARLIN_USE_ATOMIC_ADD to 1 if possible.\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=7579)\u001b[0m INFO 02-06 16:55:08 [marlin_utils.py:353] You are running Marlin kernel with bf16 on GPUs before SM90. You can consider change to fp16 to achieve better performance if possible.\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=7583)\u001b[0m INFO 02-06 16:55:08 [monitor.py:34] torch.compile takes 53.71 s in total\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=7574)\u001b[0m INFO 02-06 16:55:09 [gpu_worker.py:298] Available KV cache memory: 31.13 GiB\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m INFO 02-06 16:55:18 [core.py:218] init engine (profile, create kv cache, warmup model) took 67.39 seconds\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m INFO 02-06 16:55:19 [core.py:145] Batch queue is enabled with size 2\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m INFO 02-06 16:55:19 [loggers.py:142] Engine 000: vllm cache_config_info with initialization after num_gpu_blocks is: 52957\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m INFO 02-06 16:55:19 [async_llm.py:180] Torch profiler disabled. AsyncLLM CPU traces will not be collected.\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m INFO 02-06 16:55:26 [api_server.py:1692] Supported_tasks: ['generate']\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m \u001b[1;36m(EngineCore_DP0 pid=2219)\u001b[0;0m \u001b[36m(RayWorkerWrapper pid=7345)\u001b[0m INFO 02-06 16:55:17 [custom_all_reduce.py:203] Registering 4221 cuda graph addresses\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(RayWorkerWrapper pid=2657, ip=10.128.6.21)\u001b[0m INFO 02-06 16:55:18 [gpu_model_runner.py:3118] Graph capturing finished in 8 secs, took 0.82 GiB\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(RayWorkerWrapper pid=2657, ip=10.128.6.21)\u001b[0m INFO 02-06 16:55:18 [gpu_worker.py:391] Free memory on device (78.76/79.25 GiB) on startup. Desired GPU memory utilization is (0.9, 71.33 GiB). Actual usage is 41.67 GiB for weight, 1.27 GiB for peak activation, 1.11 GiB for non-torch memory, and 0.82 GiB for CUDAGraph memory. Replace gpu_memory_utilization config with `--kv-cache-memory=28241190297` to fit into requested memory, or `--kv-cache-memory=36225401856` to fully utilize gpu memory. Current kv cache memory in use is 29283474841 bytes.\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m WARNING 02-06 16:55:27 [__init__.py:1695] Default sampling parameters have been overridden by the model's Hugging Face generation config recommended from the model creator. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m INFO 02-06 16:55:27 [serving_responses.py:130] Using default chat sampling params from model: {'temperature': 0.6, 'top_p': 0.95}\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m INFO 02-06 16:55:27 [serving_chat.py:137] Using default chat sampling params from model: {'temperature': 0.6, 'top_p': 0.95}\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m INFO 02-06 16:55:27 [serving_completion.py:76] Using default completion sampling params from model: {'temperature': 0.6, 'top_p': 0.95}\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m INFO 2026-02-06 16:55:27,309 default_LLMServer:my-deepseek-r1 944l93yn -- Started vLLM engine.\n",
      "\u001b[36m(ServeReplica:default:LLMServer:my-deepseek-r1 pid=493, ip=10.128.7.238)\u001b[0m INFO 2026-02-06 16:55:27,368 default_LLMServer:my-deepseek-r1 944l93yn 2e081603-576e-40b8-9d10-e88096354fb0 -- CALL llm_config OK 1.9ms\n",
      "Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 60/67 [00:05<00:00, 10.63it/s]\u001b[32m [repeated 5x across cluster]\u001b[0mr pid=7163)\u001b[0m \n",
      "Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:07<00:00,  9.55it/s]\u001b[32m [repeated 7x across cluster]\u001b[0mr pid=7163)\u001b[0m \n",
      "INFO 2026-02-06 16:55:28,168 serve 751227 -- Application 'default' is ready at http://0.0.0.0:8000/.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!serve run serve_deepseek_r1:app --non-blocking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d18e22",
   "metadata": {},
   "source": [
    "Deployment typically takes a few minutes as the cluster is provisioned, the vLLM server starts, and the model is downloaded. \n",
    "\n",
    "---\n",
    "\n",
    "### Send requests\n",
    "\n",
    "Your endpoint is available locally at `http://localhost:8000` and you can use a placeholder authentication token for the OpenAI client, for example `\"FAKE_KEY\"`.\n",
    "\n",
    "Example curl:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1dd345c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"chatcmpl-c717195a-d909-4693-b492-1f5c49234027\",\"object\":\"chat.completion\",\"created\":1770425795,\"model\":\"my-deepseek-r1\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"\\n\\nThe result of 2 + 2 is **4**. \\n\\n**Step-by-Step Explanation:**\\n1. **Start with the number 2.**\\n2. **Add 2 to it:**  \\n   2 (first number) + 2 (second number).\\n3. **Combine the quantities:**  \\n   When you have 2 items and add 2 more, the total becomes 4.\\n4. **Verification:**  \\n   Using fingers, number lines, or basic arithmetic properties confirms the result. In base 10 (standard numbering), 2 + 2 always equals 4.\\n\\n**Answer:** 4.\",\"refusal\":null,\"annotations\":null,\"audio\":null,\"function_call\":null,\"tool_calls\":[],\"reasoning_content\":\"Okay, so I need to figure out what 2 plus 2 is. Hmm, let's start by recalling basic addition. I know that when you add two numbers, you're combining their values. So if I have 2 apples and someone gives me 2 more apples, how many apples do I have in total?\\n\\nLet me count them. One, two... then adding two more makes three, four. So that's 4 apples altogether. Wait, is that right? Let me check again. If I start at 2 and then add 2 more, I can count up: 2, then 3 (that's one), and 4 (that's two). Yeah, so 2 plus 2 equals 4.\\n\\nBut maybe I should verify using another method. Maybe using my fingers. Hold up two fingers on one hand and two on the other. Now, if I count all the fingers I'm holding up, that's 1, 2, 3, 4. Yep, still 4. \\n\\nAnother way to think about it is using number lines. Starting at 0, move 2 units to the right, landing on 2. Then move another 2 units to the right. That should land me on 4. So 2 + 2 = 4.\\n\\nWait, could there be any situation where 2 + 2 doesn't equal 4? Like in different number systems or bases? Let's see. In base 10, which is what we commonly use, 2 + 2 is definitely 4. If we were in base 3, what would happen? In base 3, the numbers go 0, 1, 2, then 10. So 2 + 2 in base 3 would be 11, because 2 + 2 is 4 in decimal, and 4 divided by 3 is 1 with a remainder of 1. But the question didn't specify a base, so it's safe to assume base 10. Therefore, the answer is 4.\\n\\nAlternatively, maybe using some mathematical properties. Addition is commutative and associative, so the order doesn't matter. If I break it down, 2 + 2 is the same as 2 times 2, but wait, no, multiplication is different. 2 times 2 is 4 as well, but that's a different operation. But addition here is straightforward. \\n\\nI could also think of it algebraically. Letâ€™s say x = 2 + 2. To solve for x, we just perform the addition. There's no variable to solve for here, so x is simply 4. \\n\\nIs there any trick to this question? Sometimes people ask simple questions to see if you overcomplicate them. But given the straightforward wording, it's likely just a basic arithmetic problem. So unless there's some hidden context or trick, the answer should be 4.\\n\\nJust to make sure, maybe check with a calculator. If I input 2 + 2 and press equals, the result is 4. Yep, that confirms it. So after considering different methods and verifying, I'm confident that 2 + 2 equals 4.\\n\"},\"logprobs\":null,\"finish_reason\":\"stop\",\"stop_reason\":null,\"token_ids\":null}],\"service_tier\":null,\"system_fingerprint\":null,\"usage\":{\"prompt_tokens\":13,\"total_tokens\":810,\"completion_tokens\":797,\"prompt_tokens_details\":null},\"prompt_logprobs\":null,\"prompt_token_ids\":null,\"kv_transfer_params\":null}"
     ]
    }
   ],
   "source": [
    "!curl -X POST http://localhost:8000/v1/chat/completions \\\n",
    "  -H \"Authorization: Bearer FAKE_KEY\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -d '{ \"model\": \"my-deepseek-r1\", \"messages\": [{\"role\": \"user\", \"content\": \"What is 2 + 2?\"}] }'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca5e4fd",
   "metadata": {},
   "source": [
    "Example Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "584f01f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"asctime\": \"2026-02-06 16:58:36,204\", \"levelname\": \"INFO\", \"message\": \"HTTP Request: POST http://localhost:8000/v1/chat/completions \\\"HTTP/1.1 200 OK\\\"\", \"filename\": \"_client.py\", \"lineno\": 1025, \"process\": 750734, \"job_id\": \"23000000\", \"worker_id\": \"23000000ffffffffffffffffffffffffffffffffffffffffffffffff\", \"node_id\": \"1a6ddbbb716b74256e415b58e3dca445abdb4074bbfecbc482406ab0\", \"timestamp_ns\": 1770425916204943427}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, the user wants a joke. Let me think. I need something light and not offensive. Maybe a pun or a play on words. What's a classic setup? Maybe involving animals or everyday situations. How about something with a skeleton? Skeletons are funny because they're spooky but not too scary. Oh, right, the skeleton in the closet joke. Wait, but that's common. Let me see. Why don't skeletons fight each other? Because they don't have the guts! That's a good one. Guts can mean both courage and organs, which they lack. Simple and clean. Alternatively, maybe a math joke? Why was the equal sign so humble? Because he knew he wasn't less than or greater than anyone else. That's also good. But the skeleton one is more universally funny. Let's go with that.\n",
      "\n",
      "\n",
      "Sure! Here's a lighthearted one:  \n",
      "\n",
      "Why donâ€™t skeletons fight each other?  \n",
      "â€¦They donâ€™t have the *guts*!  \n",
      "\n",
      "(Donâ€™t worry, Iâ€™ll stick to my day job. ðŸ˜…)"
     ]
    }
   ],
   "source": [
    "#client.py\n",
    "from urllib.parse import urljoin\n",
    "from openai import OpenAI\n",
    "\n",
    "API_KEY = \"FAKE_KEY\"\n",
    "BASE_URL = \"http://localhost:8000\"\n",
    "\n",
    "client = OpenAI(base_url=urljoin(BASE_URL, \"v1\"), api_key=API_KEY)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"my-deepseek-r1\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Tell me a joke\"}],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "# Stream and print JSON\n",
    "for chunk in response:\n",
    "    # Stream reasoning content first\n",
    "    if hasattr(chunk.choices[0].delta, \"reasoning_content\"):\n",
    "        data_reasoning = chunk.choices[0].delta.reasoning_content\n",
    "        if data_reasoning:\n",
    "            print(data_reasoning, end=\"\", flush=True)\n",
    "    # Later, stream the final answer\n",
    "    if hasattr(chunk.choices[0].delta, \"content\"):\n",
    "        data_content = chunk.choices[0].delta.content\n",
    "        if data_content:\n",
    "            print(data_content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5fd1fb",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Shutdown\n",
    "\n",
    "Shutdown your LLM service: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c03cdb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-06 16:58:54,931\tSUCC scripts.py:774 -- \u001b[32mSent shutdown request; applications will be deleted asynchronously.\u001b[39m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!serve shutdown -y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc223463",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Deploy to production with Anyscale services\n",
    "\n",
    "For production deployment, use Anyscale services to deploy the Ray Serve app to a dedicated cluster without modifying the code. Anyscale provides scalability, fault tolerance, and load balancing, keeping the service resilient against node failures, high traffic, and rolling updates, while also automating multi-node setup and autoscaling for large models like DeepSeek-R1.\n",
    "\n",
    "**Beware**: this is an expensive deployment. At the time of writing, the deployment cost is around \\$110 USD per hour in the `us-west-2` AWS region using on-demand instances. Because this node has a high amount of inter-node traffic, and cross-zone traffic is expensive (around \\$0.02 per GB), it's recommended to *disable cross-zone autoscaling*. This demo is pre-configured with cross-zone autoscaling disabled for your convenience.\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "The following template runs only on H100 GPUs in your self-hosted Anyscale cloud, as H100s aren't available in Anyscaleâ€™s public cloud. This example uses two nodes of type *8xH100-80&nbsp;GB:208CPU-1830&nbsp;GB* on an AWS cloud.\n",
    "\n",
    "To provision nodes with 1000 GB of disk capacity, see [Changing the default disk size for GCP clusters](https://docs.anyscale.com/configuration/compute/gcp#disk-size) for Google Cloud Platform (GCP) or [Changing the default disk size for AWS clusters](https://docs.anyscale.com/configuration/compute/aws#disk-size) for Amazon Web Services (AWS). \n",
    "\n",
    "---\n",
    "\n",
    "### Launch the service\n",
    "\n",
    "Anyscale provides out-of-the-box images (`anyscale/ray-llm`), which come pre-loaded with Ray Serve LLM, vLLM, and all required GPU/runtime dependencies. This makes it easy to get started without building a custom image.\n",
    "\n",
    "Create your Anyscale service configuration in a new `service.yaml` file:\n",
    "```yaml\n",
    "#service.yaml\n",
    "name: deploy-deepseek-r1\n",
    "image_uri: anyscale/ray-llm:2.49.0-py311-cu128 # Anyscale Ray Serve LLM image. Use `containerfile: ./Dockerfile` to use a custom Dockerfile.\n",
    "compute_config:\n",
    "  auto_select_worker_config: true \n",
    "  # Change default disk size to 1000GB\n",
    "  advanced_instance_config:\n",
    "    ## AWS ##\n",
    "    BlockDeviceMappings:\n",
    "      - Ebs:\n",
    "        - VolumeSize: 1000\n",
    "          VolumeType: gp3\n",
    "          DeleteOnTermination: true\n",
    "        DeviceName: \"/dev/sda1\"\n",
    "    #########\n",
    "    ## GCP ##\n",
    "    #instanceProperties:\n",
    "    #  disks:\n",
    "    #    - boot: true\n",
    "    #      auto_delete: true\n",
    "    #      initialize_params:\n",
    "    #        - disk_size_gb: 1000\n",
    "    #########\n",
    "  \n",
    "working_dir: .\n",
    "cloud:\n",
    "applications:\n",
    "# Point to your app in your Python module\n",
    "- import_path: serve_deepseek_r1:app\n",
    "```\n",
    "\n",
    "Deploy your service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa1c6108",
   "metadata": {
    "pygments_lexer": "bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ray/anaconda3/lib/python3.11/site-packages/google/rpc/__init__.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "\u001b[1m\u001b[36m(anyscale +1.4s)\u001b[0m \u001b[0m\u001b[0m\u001b[0m\u001b[0mUpdating existing service 'deploy-deepseek-r1'.\u001b[0m\n",
      "\u001b[0m\u001b[1m\u001b[36m(anyscale +3.8s)\u001b[0m \u001b[0m\u001b[0m\u001b[0m\u001b[0mCreated compute config: 'compute-v1-9806d5b4d0b5a96919faa02648ca9808:1'\u001b[0m\n",
      "\u001b[0m\u001b[1m\u001b[36m(anyscale +3.8s)\u001b[0m \u001b[0m\u001b[0m\u001b[0m\u001b[0mView the compute config in the UI: 'https://console.anyscale.com/v2/cld_a6j8iubw9rqbyigfwk9fut4amk/compute-configs/cpt_cfy6baqr735ajukmcnd7gchb9d'\u001b[0m\n",
      "\u001b[0m\u001b[1m\u001b[36m(anyscale +4.7s)\u001b[0m \u001b[0m\u001b[0m\u001b[0m\u001b[0mUploading local dir '.' to cloud storage.\u001b[0m\n",
      "\u001b[0m\u001b[1m\u001b[36m(anyscale +6.2s)\u001b[0m \u001b[0m\u001b[0m\u001b[0m\u001b[0mIncluding workspace-managed pip dependencies.\u001b[0m\n",
      "\u001b[0m\u001b[1m\u001b[36m(anyscale +7.2s)\u001b[0m \u001b[0m\u001b[0m\u001b[0m\u001b[0mService 'deploy-deepseek-r1' deployed (version ID: wuiu7uxy).\u001b[0m\n",
      "\u001b[0m\u001b[1m\u001b[36m(anyscale +7.2s)\u001b[0m \u001b[0m\u001b[0m\u001b[0m\u001b[0mView the service in the UI: 'https://console.anyscale.com/services/service2_18jcv96zi1x56m7h43ccv9av62'\u001b[0m\n",
      "\u001b[0m\u001b[1m\u001b[36m(anyscale +7.2s)\u001b[0m \u001b[0m\u001b[0m\u001b[0m\u001b[0mQuery the service once it's running using the following curl command (add the path you want to query):\u001b[0m\n",
      "\u001b[0m\u001b[1m\u001b[36m(anyscale +7.2s)\u001b[0m \u001b[0m\u001b[0m\u001b[0m\u001b[0mcurl -H \"Authorization: Bearer nQLEZeCK9Fag-9KAD-c9AXz7167nYfi_eZVjQr0nS0g\" https://deploy-deepseek-r1-kwkre.cld-a6j8iubw9rqbyigf.s.anyscaleuserdata.com/\u001b[0m\n",
      "\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "!anyscale service deploy -f service.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18226fd7",
   "metadata": {},
   "source": [
    "**Note:** If your model is gated, make sure to pass your Hugging Face token to the service with `--env HF_TOKEN=<YOUR_HUGGINGFACE_TOKEN>`\n",
    "\n",
    "**Custom Dockerfile**  \n",
    "You can customize the container by building your own Dockerfile. In your Anyscale Service config, reference the Dockerfile with `containerfile` (instead of `image_uri`):\n",
    "\n",
    "```yaml\n",
    "# service.yaml\n",
    "# Replace:\n",
    "# image_uri: anyscale/ray-llm:2.49.0-py311-cu128\n",
    "\n",
    "# with:\n",
    "containerfile: ./Dockerfile\n",
    "```\n",
    "\n",
    "See the [Anyscale base images](https://docs.anyscale.com/reference/base-images) for details on what each image includes.\n",
    "\n",
    "---\n",
    "\n",
    "### Send requests \n",
    "\n",
    "The `anyscale service deploy` command output shows both the endpoint and authentication token:\n",
    "```console\n",
    "(anyscale +3.9s) curl -H \"Authorization: Bearer <YOUR-TOKEN>\" <YOUR-ENDPOINT>\n",
    "```\n",
    "You can also retrieve both from the service page in the Anyscale console. Click the **Query** button at the top. See [Send requests](#send-requests) for example requests, but make sure to use the correct endpoint and authentication token.  \n",
    "\n",
    "---\n",
    "\n",
    "### Access the Serve LLM dashboard\n",
    "\n",
    "See [Enable LLM monitoring](#enable-llm-monitoring) for instructions on enabling LLM-specific logging. To open the Ray Serve LLM dashboard from an Anyscale service:\n",
    "1. In the Anyscale console, go to your **Service** or **Workspace**\n",
    "2. Navigate to the **Metrics** tab\n",
    "3. Click **View in Grafana** and click **Serve LLM Dashboard**\n",
    "\n",
    "---\n",
    "\n",
    "### Shutdown \n",
    " \n",
    "Shutdown your Anyscale service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "211d5baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ray/anaconda3/lib/python3.11/site-packages/google/rpc/__init__.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "\u001b[1m\u001b[36m(anyscale +2.4s)\u001b[0m \u001b[0m\u001b[0m\u001b[0m\u001b[0mService service2_18jcv96zi1x56m7h43ccv9av62 terminate initiated.\u001b[0m\n",
      "\u001b[0m\u001b[1m\u001b[36m(anyscale +2.4s)\u001b[0m \u001b[0m\u001b[0m\u001b[0m\u001b[0mView the service in the UI at https://console.anyscale.com/services/service2_18jcv96zi1x56m7h43ccv9av62\u001b[0m\n",
      "\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "!anyscale service terminate -n deploy-deepseek-r1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8fba49",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Enable LLM monitoring\n",
    "\n",
    "The *Serve LLM dashboard* offers deep visibility into model performance, latency, and system behavior, including:\n",
    "\n",
    "* Token throughput (tokens/sec)\n",
    "* Latency metrics: Time To First Token (TTFT), Time Per Output Token (TPOT)\n",
    "* KV cache utilization\n",
    "\n",
    "To enable these metrics, go to your LLM config and set `log_engine_metrics: true`. Ensure vLLM V1 is active with `VLLM_USE_V1: \"1\"`. \n",
    "**Note:** `VLLM_USE_V1: \"1\"` is the default value with `ray >= 2.48.0` and can be omitted.\n",
    "```yaml\n",
    "applications:\n",
    "- ...\n",
    "  args:\n",
    "    llm_configs:\n",
    "      - ...\n",
    "        runtime_env:\n",
    "          env_vars:\n",
    "            VLLM_USE_V1: \"1\"\n",
    "        ...\n",
    "        log_engine_metrics: true\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Improve concurrency\n",
    "\n",
    "Ray Serve LLM uses [vLLM](https://docs.vllm.ai/en/stable/) as its backend engine, which logs the *maximum concurrency* it can support based on your configuration.  \n",
    "\n",
    "Example log:\n",
    "```console\n",
    "INFO 07-30 11:56:04 [kv_cache_utils.py:637] Maximum concurrency for 32,768 tokens per request: 29.06x\n",
    "```\n",
    "\n",
    "The following are a few ways to improve concurrency depending on your model and hardware:  \n",
    "\n",
    "**Reduce `max_model_len`**  \n",
    "Lowering `max_model_len` reduces the memory needed for KV cache.\n",
    "\n",
    "**Example**: Running DeepSeek-R1 on 2 nodes with 8xH100-80&nbsp;GB GPUs each:\n",
    "* `max_model_len = 32,768` â†’ concurrency â‰ˆ 29\n",
    "* `max_model_len = 16,384` â†’ concurrency â‰ˆ 58\n",
    "\n",
    "**Use distilled or quantized models**  \n",
    "Quantizing or distilling your model reduces its memory footprint, freeing up space for more KV cache and enabling more concurrent requests. For example, see [`deepseek-ai/DeepSeek-R1-Distill-Llama-70B`](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-70B) for a distilled version of DeepSeek-R1.\n",
    "\n",
    "\n",
    "**Upgrade to GPUs with more memory**  \n",
    "Some GPUs provide significantly more room for KV cache and allow for higher concurrency out of the box.\n",
    "\n",
    "**Scale with more replicas**  \n",
    "In addition to tuning per-replica concurrency, you can scale *horizontally* by increasing the number of replicas in your config.  \n",
    "Raising the replica count increases the total number of concurrent requests your service can handle, especially under sustained or bursty traffic.\n",
    "```yaml\n",
    "deployment_config:\n",
    "  autoscaling_config:\n",
    "    min_replicas: 1\n",
    "    max_replicas: 4\n",
    "```\n",
    "\n",
    "*For more details on tuning strategies, hardware guidance, and serving configurations, see [Choose a GPU for LLM serving](https://docs.anyscale.com/llm/serving/gpu-guidance) and [Tune parameters for LLMs on Anyscale services](https://docs.anyscale.com/llm/serving/parameter-tuning).*\n",
    "\n",
    "---\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "**Hugging Face auth errors**  \n",
    "Some models, such as Llama-3.1, are gated and require prior authorization from the organization. See your modelâ€™s documentation for instructions on obtaining access.\n",
    "\n",
    "**Out-Of-Memory errors**  \n",
    "Outâ€‘ofâ€‘memory (OOM) errors are one of the most common failure modes when deploying LLMs, especially as model sizes, and context length increase.  \n",
    "See [Troubleshooting Guide](https://docs.anyscale.com/overview) for common errors and how to fix them.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this tutorial, you deployed a large-sized LLM with Ray Serve LLM, from development to production. You learned how to configure Ray Serve LLM, deploy your service on your Ray cluster, and how to send requests. You also learned how to monitor your app and troubleshoot common issues."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
